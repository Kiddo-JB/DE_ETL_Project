{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLwBmhL0HSLVEHZhs8k4bT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kiddo-JB/DE_ETL_Project/blob/main/DE_ETL_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ETL PROJECT"
      ],
      "metadata": {
        "id": "dEr-_GJQ83Jt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bViAm3538R7H"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "import pandas as pd\n",
        "import json\n",
        "import xml.etree.ElementTree as ET\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths\n",
        "LOG_FILE = 'log_file.txt'\n",
        "TRANSFORMED_DATA = 'transformed_data.csv'"
      ],
      "metadata": {
        "id": "HORZlF1lINoF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a log message to a text file.\n",
        "def log_message(message):\n",
        "    with open(LOG_FILE, 'a') as log_file:\n",
        "      log_file.write(f\"{datetime.now()} - {message}\\n\")"
      ],
      "metadata": {
        "id": "3gJK3dbbIfJy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IGuyHcdxIoZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Methods"
      ],
      "metadata": {
        "id": "UgDtcYYMIrGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_csv(file_path):\n",
        "   # Extract data from a CSV file.\n",
        "    log_message(f\"Extracting data from CSV file: {file_path}\")\n",
        "    return pd.read_csv(file_path)\n",
        "\n",
        "def extract_json(file_path):\n",
        "    # Extract data from a JSON file.\n",
        "    log_message(f\"Extracting data from JSON file: {file_path}\")\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = [json.loads(line) for line in file]\n",
        "\n",
        "    return pd.json_normalize(data)\n",
        "\n",
        "\n",
        "def extract_xml(file_path):\n",
        "   #Extract data from an XML file.\n",
        "    log_message(f\"Extracting data from XML file: {file_path}\")\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = [{elem.tag: elem.text for elem in child} for child in root]\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def extract_data(file_paths):\n",
        "    #Master function to extract data based on file type.\n",
        "    log_message(\"Starting data extraction\")\n",
        "    all_data = []\n",
        "    for file_path in file_paths:\n",
        "        if file_path.endswith('.csv'):\n",
        "            all_data.append(extract_csv(file_path))\n",
        "        elif file_path.endswith('.json'):\n",
        "            all_data.append(extract_json(file_path))\n",
        "        elif file_path.endswith('.xml'):\n",
        "            all_data.append(extract_xml(file_path))\n",
        "        else:\n",
        "            log_message(f\"Unsupported file format: {file_path}\")\n",
        "    combined_data = pd.concat(all_data).drop_duplicates()\n",
        "    log_message(\"Data extraction completed\")\n",
        "    return combined_data"
      ],
      "metadata": {
        "id": "ktNO565-IvAB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformation Method\n"
      ],
      "metadata": {
        "id": "rlQ2grIxI3AJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_data(df):\n",
        "    #Transform the data (e.g., unit conversions, cleaning).\n",
        "    log_message(\"Starting data transformation\")\n",
        "    # Convert heights to meters and weights to kilograms\n",
        "    for col in df.columns:\n",
        "        if col.lower() =='height':\n",
        "            df['height_in_meters'] = (df[col].astype(float) * 0.0254).round(2)\n",
        "            df.drop(columns=[col], inplace=True)\n",
        "        if col.lower() =='weight':\n",
        "            df['weight_in_kilograms'] = (df[col].astype(float) * 0.453592).round(2)\n",
        "            df.drop(columns=[col], inplace=True)\n",
        "    log_message(\"Data transformation completed\")\n",
        "    return df"
      ],
      "metadata": {
        "id": "SMv-iMaKI6n5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Method"
      ],
      "metadata": {
        "id": "qg-Sc9cPJATZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(df, output_path):\n",
        "    #Load the transformed data into a CSV file.\n",
        "    log_message(f\"Loading data into CSV file: {output_path}\")\n",
        "    df.to_csv(output_path)\n",
        "    log_message(f\"Data successfully loaded into {output_path}\")\n"
      ],
      "metadata": {
        "id": "fbE9FLfJJGbp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Method"
      ],
      "metadata": {
        "id": "JyjD_hJYJLyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def etl_process(file_paths, output_path):\n",
        "    # ETL process: Extract, Transform, Load.\n",
        "    log_message(\"Starting ETL process\")\n",
        "\n",
        "    # Extract\n",
        "    extracted_data = extract_data(file_paths)\n",
        "\n",
        "    # Transform\n",
        "    transformed_data = transform_data(extracted_data)\n",
        "\n",
        "    # Load\n",
        "    load_data(transformed_data, output_path)\n",
        "\n",
        "    log_message(\"ETL process completed\")\n",
        "\n",
        "\n",
        "file_paths = ['./source1.csv', './source1.json', './source1.xml','./source2.csv', './source2.json', './source2.xml','./source3.csv', './source3.json', './source3.xml']\n",
        "etl_process(file_paths, TRANSFORMED_DATA)"
      ],
      "metadata": {
        "id": "TzunJt-6JK0I"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}